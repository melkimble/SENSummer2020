{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Data\n",
    "Lesson 13 with **\n",
    "https://cyberhelp.sesync.org/online-data-lesson/course/\n",
    "\n",
    "## Lesson Objectives\n",
    "* Distinguish three types of online data\n",
    "* Break down how web services use HTTP\n",
    "* Learn Python tools for data acquisition\n",
    "\n",
    "## Specific Achievements\n",
    "* Programatically acquire data embedded in a web page\n",
    "* Request data through a REST API\n",
    "* Use the census package to acquire data\n",
    "* Use SQLite for caching\n",
    "\n",
    "## Why script data acquistion?\n",
    "* Too time intensive to acquire manually\n",
    "* Integrate updated or new data\n",
    "* Reproducibility\n",
    "* There‚Äôs an API between you and the data\n",
    "\n",
    "## Acquiring Online Data\n",
    "Data is available on the web in many different forms. How difficult is it to acquire that data to run analyses? It depends which of three approaches the data source requires:\n",
    "\n",
    "* Web scraping\n",
    "* Web service or API\n",
    "* API wrapper\n",
    "\n",
    "## Web Scraping üôÅ\n",
    "If a web browser can read HTML and JavaScript and display a human readable page, why can‚Äôt you write a program (a ‚Äúbot‚Äù) to read HTML and JavaScript and store the data?\n",
    "\n",
    "## Web Service or API üòâ\n",
    "An Application Programming Interface (API, as opposed to GUI) that is compatible with passing data around the internet using HTTP (Hyper-text Transfer Protocol). This is not the fastest protocol for moving large datasets, but it is universal (it underpins web browsers, after all).\n",
    "\n",
    "## API Wrapper üòÇ\n",
    "Major data providers can justify writing a package, specific to your language of choice (e.g. Python or R), that facilitates accessing the data they provide through a web service. Sadly, not all do so.\n",
    "\n",
    "### Requests\n",
    "That ‚Äúhttp‚Äù at the beginning of the URL for a possible data source is a protocol‚Äîan understanding between a client and a server about how to communicate. The client does not have to be a web browser, so long as it knows the protocol. After all, servers exist to serve.\n",
    "\n",
    "The requests package provides a simple interface to issuing HTTP requests and handling the response. Here‚Äôs an example using an XKCD comic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('https://xkcd.com/869')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response is still binary. It takes a browser-like parser to translate the raw content into an HTML document. BeautifulSoup does a fair job, while making no attempt to ‚Äúrender‚Äù a human-readable page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching the document for desired content is the hard part. This search uses a CSS query to find the image below a section of the document with attribute id = comic.\n",
    " \n",
    "soo .. next 4 chunks are repeats; website has slightly different code than the worksheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "doc = BeautifulSoup(response.text, 'lxml')\n",
    "'\\n'.join(doc.prettify().splitlines()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = doc.select('#comic > img')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "doc = BeautifulSoup(response.text, 'lxml')\n",
    "print('\\n'.join(\n",
    "    doc.prettify().splitlines()[0:10]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = doc.select_one('#comic > img')\n",
    "img['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was that so bad?\n",
    "Pages designed for humans are increasingly harder to parse programmatically.\n",
    "\n",
    "* Servers provide different responses based on client ‚Äúmetadata‚Äù\n",
    "* JavaScript often needs to be executed by the client\n",
    "* The HTML <table> is drifting into obscurity (mostly for the better)\n",
    "    \n",
    "### HTML Table\n",
    "    Sites with easily accessible html tables nowadays may be specifically intended to be parsed programmatically, rather than browsed by a human reader. The US Census provides some documentation for their data services in a massive table:\n",
    "\n",
    "https://api.census.gov/data/2017/acs/acs5/variables.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vars = (\n",
    "  pd\n",
    "  .read_html('https://api.census.gov/data/2017/acs/acs5/variables.html')\n",
    "  .pop()\n",
    ")\n",
    "vars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our data manipulation tools to search this unwieldy documentation for variables of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (\n",
    "  vars['Label']\n",
    "  .str\n",
    "  .contains('Median household income')\n",
    ")\n",
    "vars.loc[idx, ['Name', 'Label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Services\n",
    "The US Census Bureau provides access to its vast stores of demographic data over the Web via their API at https://api.census.gov.\n",
    "\n",
    "The I in GUI is for interface‚Äîit‚Äôs the same in API, where buttons and drop-down menus are replaced by functions and object attributes.\n",
    "\n",
    "Instead of interfacing with a user, this kind of interface is suitable for use in programming another software application. In the case of the Census, the main component of the application is some relational database management system. There are several GUIs designed for humans to query the Census database; the Census API is meant for communication between your program (i.e. script) and their application.\n",
    "\n",
    "You‚Äôll often see the acronym ‚ÄúREST API.‚Äù In this context, REST stands for Representational state transfer. This refers to a set of standards that help ensure that the Web service works well with any computer system it may interact with.\n",
    "\n",
    "Inspect this URL in your browser.\n",
    "\n",
    "In a web service, the already universal system for transferring data over the internet, known as HTTP, is half of the interface. All you really need is documentation for how to construct the URL in a standards-compliant way that the service will recognize.\n",
    "\n",
    "Section\tDescription\n",
    "https://\tscheme\n",
    "api.census.gov\tauthority, or simply domain if there‚Äôs no user authentication\n",
    "/data/2015/acs5\tpath to a resource within a hierarchy\n",
    "?\tbeginning of the query component of a URL\n",
    "get=NAME\tfirst query parameter\n",
    "&\tquery parameter separator\n",
    "for=county\tsecond query parameter\n",
    "&\tquery parameter separator\n",
    "in=state:*\tthird query parameter\n",
    "#\tbeginning of the fragment component of a URL\n",
    "irrelephant\ta document section, it isn‚Äôt even sent to the server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://api.census.gov/data/2017/acs/acs5'\n",
    "query = {\n",
    "  'get': 'NAME,B19013_001E',\n",
    "  'for': 'tract:*',\n",
    "  'in': 'state:24',\n",
    "}\n",
    "response = requests.get(path, params=query)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Header\n",
    "The response from the API is a bunch of 0s and 1s, but part of the HTTP protocol is to include a ‚Äúheader‚Äù with information about how to decode the body of the response.\n",
    "\n",
    "Most REST APIs return as the ‚Äúcontent‚Äù either:\n",
    "\n",
    "1. Javascript Object Notation (JSON)\n",
    "* a UTF-8 encoded string of key-value pairs, where values may be lists\n",
    "* e.g. {'a':24, 'b': ['x', 'y', 'z']}\n",
    "2. eXtensible Markup Language (XML)\n",
    "* a nested <tag></tag> hierarchy serving the same purpose\n",
    "\n",
    "The header from Census says the content type is JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.headers['Content-Type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Content\n",
    "Use a JSON reader to extract a Python object. To read it into a pandas DataFrame, use pandas‚Äô read_json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(response.content)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Keys & Limits\n",
    "Most servers request good behavior, others enforce it.\n",
    "\n",
    "* Size of single query\n",
    "* Rate of queries (calls per second, or per day)\n",
    "* User credentials specified by an API key\n",
    "\n",
    "From the Census FAQ What Are the Query Limits?:\n",
    "\n",
    "You can include up to 50 variables in a single API query and can make up to 500 queries per IP address per day‚Ä¶ Please keep in mind that all queries from a business or organization having multiple employees might employ a proxy service or firewall. This will make all of the users of that business or organization appear to have the same IP address.\n",
    "\n",
    "### Specialized Packages\n",
    "The third tier of access to online data is much preferred, if it exists: a dedicated package in your programming language‚Äôs repository (PyPI or CRAN).\n",
    "\n",
    "* Additional guidance on query parameters\n",
    "* Returns data in native formats\n",
    "* Handles all ‚Äúencoding‚Äù problems\n",
    "\n",
    "The census package is a user-contributed suite of tools that streamline access to the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from census import Census\n",
    "\n",
    "key = None\n",
    "c = Census(key, year=2017)\n",
    "c.acs5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to using the API directly via the requests package:\n",
    "\n",
    "### Pros\n",
    "\n",
    "* More concise code, quicker development\n",
    "* Package documentation (if present) is usually more user-friendly than API documentaion.\n",
    "* May allow seamless update if API changes\n",
    "\n",
    "### Cons\n",
    "\n",
    "* No guarantee of updates\n",
    "* Possibly limited in scope\n",
    "\n",
    "Query the Census ACS5 (American Community Survey) for the variable B19001_001E (median annual household income, in dollars) and each entity‚Äôs NAME.\n",
    "\n",
    "The American Community Survey (ACS) is a yearly survey that provides detailed population and housing information at fine geographic scale across the United States. Much of the census package is dedicated to accessing the ACS data. ACS5 refers to a five-year average of the annual surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = ('NAME', 'B19013_001E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code pulls the variables NAME and B19001_001E from all census tracts and all counties in the state with ID 24 (Maryland). The census package converts the JSON string into a Python dictionary. (No need to check headers.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = c.acs5.state_county_tract(\n",
    "    variables,\n",
    "    state_fips='24',\n",
    "    county_fips=Census.ALL,\n",
    "    tract=Census.ALL,\n",
    ")\n",
    "response[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas DataFrame() constructor will accept the list of dictionaries as the sole argument, taking column names from ‚Äúkeys‚Äù. This code also removes values less than zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "  pd\n",
    "  .DataFrame(response)\n",
    "  .query(\"B19013_001E >= 0\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The seaborn package provides some nice, quick visualizations. Here we create boxplots showing the income distribution among census tracts within each county in Maryland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.boxplot(\n",
    "  data = df,\n",
    "  x = 'county',\n",
    "  y = 'B19013_001E',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paging & Stashing\n",
    "\n",
    "A common strategy that web service providers take to balance their load is to limit the number of records a single API request can return. The user ends up having to flip through ‚Äúpages‚Äù with the API, handling the response content at each iteration. Options for stashing data are:\n",
    "\n",
    "1. Store it all in memory, write to file at the end.\n",
    "2. Append each response to a file, writing frequently.\n",
    "3. Offload these decisions to database management software.\n",
    "\n",
    "The data.gov API provides a case in point. Data.gov is a service provided by the U.S. federal government to make data available from across many government agencies. It hosts a catalog of raw data and of many other APIs from across government. Among the APIs catalogued by data.gov is the FoodData Central API. The U.S. Department of Agriculture maintains a data system of nutrition information for thousands of foods. We might be interested in the relative nutrient content of different fruits.\n",
    "\n",
    "To repeat the exercise below at home, request an API key at https://api.data.gov/signup/, and store it in a file named api_key.py in your working directory. The file should contain the single line API_KEY = your many digit key.\n",
    "\n",
    "Load the API_KEY variable by importing it from the file you saved it in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_key import API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run an API query for all foods with \"fruit\" in their name.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL 'Ellipsis': No schema supplied. Perhaps you meant http://Ellipsis?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2837aba44f1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m response = (\n\u001b[1;32m     11\u001b[0m     \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mhooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         )\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mproxies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxies\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mprepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mauth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mcookies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerged_cookies\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mhooks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmerge_hooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         )\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_headers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_cookies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcookies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mprepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_native_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMissingSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL 'Ellipsis': No schema supplied. Perhaps you meant http://Ellipsis?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "api = 'https://api.nal.usda.gov/fdc/v1/'\n",
    "path = 'foods/search'\n",
    "query = {\n",
    "    'api_key':API_KEY,\n",
    "    'query':'fruit',\n",
    "}\n",
    "response = (\n",
    "    requests\n",
    "    .get(api + path, params=query)\n",
    ")\n",
    "doc = response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract data from the returned JSON object, which gets mapped to a Python dictionary called doc. To inspect the return, we can list the dictionary keys.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(doc.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the value associated with the key totalHits to see how many foods matched our search term, \"fruit\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc['totalHits']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purported claimed number of results is much larger than the length of the foods array contained in this response. The query returned only the first page, with 50 items.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc['foods'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following commands prepare Python to connect to a database-in-a-file, and create empty tables in the database if they do not already exist (meaning that it is safe to re-run after you have populated the database).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Boilerplate\n",
    "The SQLAlchemy package has a lot of features, and requires you to be very precise about how to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Table Definition\n",
    "Define the tables that are going to live in the database using Python classes. For each class, its attributes will map to columns in a table. Then create a session engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, Text, Numeric\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Food(Base):\n",
    "    __tablename__ = 'food'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(Text)\n",
    "    sugar = Column(Numeric)\n",
    "    \n",
    "engine = create_engine('sqlite:///fruits.db')\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each fruit, we‚Äôll store its name and the amount of sugar (grams of sugar per 100 grams of fruit) found in the API response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = doc['foods'].pop()\n",
    "fruit['description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the names and values of the first ten nutrients for the first item returned by the query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (nutrient['nutrientName'], nutrient['value']) for nutrient in fruit['foodNutrients'][:9] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Connect (and Initialize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema import Session, Food\n",
    "\n",
    "session = Session()\n",
    "engine = session.bind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could inspect the fruit database now using any sqlite3 client: you would find one empty ‚Äúfood‚Äù table with fields ‚Äúid‚Äù, ‚Äúname‚Äù, and ‚Äúsugar‚Äù.\n",
    "\n",
    "Add a new pageSize parameter to request 100 documents per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query['pageSize'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each request, advance the query parameter pageNumber by one. The first record retrieved will be pageNumber * pageSize. Insert the fruits (the key:value pairs stored in values) in bulk to the database with engine.execute().\n",
    "\n",
    "In each iteration of the loop, we use a list comprehension to extract the value corresponding to the amount of sugar from each of the foods in the page of results returned by the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = Food.metadata.tables['food']\n",
    "for i in range(0, 10):\n",
    "    \n",
    "    # advance page and query\n",
    "    query['pageNumber'] = i \n",
    "    response = requests.get(api + path, params=query)\n",
    "    page = response.json()\n",
    "    fruits = page['foods']\n",
    "    \n",
    "    # save page with session engine\n",
    "    values = [{'name': fruit['description'],\n",
    "               'sugar': next(iter([ nutrient['value'] for nutrient in fruit['foodNutrients'] if nutrient['nutrientName'][0:5] == 'Sugar' ]), None) } for fruit in fruits]\n",
    "               \n",
    "    insert = table.insert().values(values)\n",
    "    engine.execute(insert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the records in the database by reading everything we have so far back into a DataFrame.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_sql_table('food', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don‚Äôt forget to disconnect from your database!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway\n",
    "* Web scraping is hard and unreliable, but sometimes there is no other option.\n",
    "\n",
    "* Web services are the most common resource.\n",
    "\n",
    "* Search PyPI for an API you plan to use.\n",
    "\n",
    "Web services do not always have great documentation‚Äîwhat parameters are acceptable or necessary may not be clear. Some may even be poorly documented on purpose if the API wasn‚Äôt designed for public use! Even if you plan to acquire data using the ‚Äúraw‚Äù web service, try a search for a relevant package on Python. The package documentation could help.\n",
    "\n",
    "## Exercises\n",
    "### Exercise 1\n",
    "Identify the name of the census variable in the table of ACS variables whose label includes ‚ÄúCOUNT OF THE POPULATION‚Äù. Next, use the Census API to collect the data for this variable, for every county in the U.S. state with FIPS code ‚Äò24‚Äô, into a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "Request an API key for data.gov, which will enable you to access the FoodData Central API. Use the API to collect 3 ‚Äúpages‚Äù of food results matching a search term of your choice. Modify schema.py to save the names and sugar contents of the foods into a new SQLite file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
